{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import keras\n",
    "import math\n",
    "import itertools\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from librosa import display\n",
    "from kapre.utils import Normalization2D\n",
    "from keras.models import Model\n",
    "from keras.layers import *\n",
    "from keras import backend as k\n",
    "from keras import optimizers\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, LearningRateScheduler\n",
    "from keras.preprocessing import sequence\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "#from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURES_PATH = os.path.abspath('/data/aumkar/data_asr/features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feat = np.load(os.path.join(FEATURES_PATH, 'train_feat.npy'))\n",
    "val_feat = np.load(os.path.join(FEATURES_PATH, 'val_feat.npy'))\n",
    "test_feat = np.load(os.path.join(FEATURES_PATH, 'test_feat.npy'))\n",
    "\n",
    "ytrain = np.load('ytrain.npy')\n",
    "yval = np.load('yval.npy')\n",
    "ytest = np.load('ytest.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "display.specshow(train_feat[1], x_axis='time')\n",
    "plt.colorbar()\n",
    "plt.title('MFCC')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_dim = 98\n",
    "wide = 40\n",
    "N1 = 128\n",
    "Nfc1 = 520\n",
    "Nfc2 = 120\n",
    "out_dim = 35\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def residual_block(y, i):\n",
    "    \n",
    "    shortcut = y\n",
    "    \n",
    "    y = Conv2D(N1, (1, 2), padding = 'same', activation = 'relu', dilation_rate = i)(y)\n",
    "    y = Activation('relu')(y)\n",
    "    y = BatchNormalization(axis = -1, scale = None)(y)\n",
    "\n",
    "    y = Add()([shortcut, y])\n",
    "\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input1 = Input(shape = (features_dim, wide, 1))\n",
    "\n",
    "model = (Normalization2D(int_axis = 1))(input1)\n",
    "\n",
    "model = (Permute((2, 1, 3)))(model)\n",
    "\n",
    "model = (Conv2D(N1, kernel_size = (1, 2), strides = (1, 2), padding = 'same', activation = 'relu'))(model)\n",
    "\n",
    "model = (BatchNormalization(axis = -1, scale = None))(model)\n",
    "\n",
    "res1 = residual_block(model, 2)\n",
    "\n",
    "res2 = residual_block(res1, 4)\n",
    "\n",
    "res3 = residual_block(res2, 8)\n",
    "    \n",
    "conv_ = (Conv2D(1, kernel_size = (1, 2), activation = 'relu', dilation_rate = 16))(res3)\n",
    "    \n",
    "bn = (BatchNormalization(axis = -1, scale = None))(conv_)\n",
    "    \n",
    "avg_pool = (MaxPooling2D(pool_size = 2))(bn)\n",
    "\n",
    "flat = (Flatten())(avg_pool)\n",
    "\n",
    "dense1 = (Dense(Nfc1, activation = 'relu'))(flat)\n",
    "\n",
    "#drop1 = (Dropout(0.5))(dense1)\n",
    "\n",
    "dense2 = (Dense(Nfc2, activation = 'relu'))(dense1)\n",
    "\n",
    "#drop2 = (Dropout(0.5))(dense2)\n",
    "\n",
    "out = (Dense(out_dim, activation = 'softmax'))(dense2)\n",
    "\n",
    "model_ = Model(inputs = [input1], outputs = out)\n",
    "\n",
    "adam_ = optimizers.Adam(lr = 1e-5, beta_1=0.9, beta_2=0.999, epsilon=1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_.compile(loss = 'categorical_crossentropy', optimizer = adam_, metrics = ['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batches = int(len(train_feat)/BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_generator():\n",
    "    \n",
    "    while True:\n",
    "\n",
    "        for batch in range(batches):\n",
    "            \n",
    "            x_ = []\n",
    "            data = train_feat[batch * BATCH_SIZE: (batch + 1) * BATCH_SIZE]\n",
    "            label = ytrain[batch * BATCH_SIZE: (batch + 1) * BATCH_SIZE]\n",
    "            \n",
    "            for i in data:\n",
    "                x_.append(np.reshape(i, (features_dim, wide, 1)))\n",
    "                 \n",
    "            x = np.asarray(x_)\n",
    "            yield (x, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val = []\n",
    "\n",
    "for i in range(len(val_feat)):\n",
    "    x_val.append(np.reshape(val_feat[i], (features_dim, wide, 1)))\n",
    "    \n",
    "valx = np.asarray(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step_decay(epoch):\n",
    "    initial_lrate = 0.001\n",
    "    drop = 0.4\n",
    "    epochs_drop = 10.0\n",
    "    lrate = initial_lrate * math.pow(drop, math.floor((1+epoch)/epochs_drop))\n",
    "    \n",
    "    if (lrate < 4e-5):\n",
    "        lrate = 4e-5\n",
    "      \n",
    "    print('Changing learning rate to {}'.format(lrate))\n",
    "    return lrate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrate = LearningRateScheduler(step_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpointer = ModelCheckpoint(filepath='checkpoint_asr.h5', monitor='val_categorical_accuracy', save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "earlystopper = EarlyStopping(monitor='val_categorical_accuracy', patience=10, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "history = model_.fit_generator(batch_generator(), steps_per_epoch = batches, epochs = 500, validation_data=(valx, yval), \n",
    "                              callbacks=[checkpointer, earlystopper, lrate], shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['categorical_accuracy'])\n",
    "plt.plot(history.history['val_categorical_accuracy'])\n",
    "plt.title('Categorical accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testEval = model.evaluate(np.reshape(test_feat, (len(test_feat), features_dim, wide, 1)), ytest, batch_size = BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Evaluation scores: \\nMetrics: {} \\nTest: {}'.format(model.metrics_names, testEval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DIR = os.path.normpath(os.path.join(os.path.dirname(os.path.realpath('__file__'))))\n",
    "DATA_INFO = os.path.join(ROOT_DIR, 'data_asr', 'data_info')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_files = pd.read_csv(os.path.join(DATA_INFO, 'testing_list.txt'), sep = ' ', header = None)[0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_lab = [os.path.dirname(i) for i in test_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lab = LabelEncoder()\n",
    "\n",
    "test_encode = lab.fit_transform(test_lab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(np.reshape(test_feat, (len(test_feat), features_dim, wide, 1)), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    #print(cm)\n",
    "\n",
    "    plt.figure(figsize=(25,25))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title, fontsize=30)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45, fontsize=15)\n",
    "    plt.yticks(tick_marks, classes, fontsize=15)\n",
    "\n",
    "    fmt = '.3f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt), size=11,\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True label', fontsize=30)\n",
    "    plt.xlabel('Predicted label', fontsize=30)\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['backward', 'bed', 'bird', 'cat', 'dog', 'down', 'eight', 'five', 'follow', \n",
    "          'forward', 'four', 'go', 'happy', 'house', 'learn', 'left', 'marvin', 'nine', \n",
    "          'no', 'off', 'on', 'one', 'right', 'seven', 'sheila', 'six', 'stop', 'three', 'tree',\n",
    "          'two', 'up', 'visual', 'wow', 'yes', 'zero']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(test_encode, np.argmax(y_pred, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(cm, classes, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(classification_report(test_encode, np.argmax(y_pred, 1), target_names = classes))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (asr)",
   "language": "python",
   "name": "asr"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
